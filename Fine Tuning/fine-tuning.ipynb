{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-Tuning GPT-3.5 Turbo on Custom Dataset**\n",
        "\n",
        "#### This notebook demonstrates how to fine-tune the GPT-3.5 Turbo model on a custom dataset. Our goal is to adapt GPT-3.5 Turbo to better perform on a dataset categorizing questions into different labels (e.g., HR, Legal, IT, Finance)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Install all the necessary libraries"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai json requests os time tiktoken"
      ],
      "outputs": [
        {
         
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import json\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import os\n",
        "from openai import AzureOpenAI"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709154395410
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Please set up environment variables"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting an environment variable\n",
        "os.environ['AZURE_OPENAI_ENDPOINT'] = 'xxxxxxxxxxxxxxxx' ## You can get this info from the AOAI resource info available on Azure Portal\n",
        "\n",
        "os.environ['AZURE_OPENAI_API_KEY'] = 'xxxxxxxxxxxxxxxx' ## You can get this info from the AOAI resource info available on Azure Portal\n",
        "\n",
        "os.environ['TEMP_AUTH_TOKEN'] = 'xxxxxxxxxxxxxxxx' ## To generate an authorization token, start Cloud Shell in the Azure portal and execute az account get-access-token. Use this as a temporary token for API testing and store it in a new environment variable for convenience"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709238560906
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Load the training data, validation data and testing data provided"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training set\n",
        "with open('training_data.jsonl', 'r', encoding='utf-8') as f:\n",
        "    training_dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Training dataset stats\n",
        "print(\"Number of examples in training set:\", len(training_dataset))\n",
        "print(\"First example in training set:\")\n",
        "for message in training_dataset[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "# Load the validation set\n",
        "with open('validation_data.jsonl', 'r', encoding='utf-8') as f:\n",
        "    validation_dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Validation dataset stats\n",
        "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
        "print(\"First example in validation set:\")\n",
        "for message in validation_dataset[0][\"messages\"]:\n",
        "    print(message)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of examples in training set: 350\nFirst example in training set:\n{'role': 'system', 'content': 'You are a classification model. Classify questions into different domains.'}\n{'role': 'user', 'content': 'What is the deadline for annual performance reviews?'}\n{'role': 'assistant', 'content': 'HR'}\n\nNumber of examples in validation set: 75\nFirst example in validation set:\n{'role': 'system', 'content': 'You are a classification model. Classify questions into different domains.'}\n{'role': 'user', 'content': 'How can I apply for annual leave?'}\n{'role': 'assistant', 'content': 'HR'}\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709154396091
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Token Count Validation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\") # default encoding used by gpt-4, turbo, and text-embedding-ada-002 models\n",
        "\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "files = ['training_data.jsonl', 'validation_data.jsonl']\n",
        "\n",
        "for file in files:\n",
        "    print(f\"Processing file: {file}\")\n",
        "    with open(file, 'r', encoding='utf-8') as f:\n",
        "        dataset = [json.loads(line) for line in f]\n",
        "\n",
        "    total_tokens = []\n",
        "    assistant_tokens = []\n",
        "\n",
        "    for ex in dataset:\n",
        "        messages = ex.get(\"messages\", {})\n",
        "        total_tokens.append(num_tokens_from_messages(messages))\n",
        "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
        "    \n",
        "    print_distribution(total_tokens, \"total tokens\")\n",
        "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
        "    print('*' * 50)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Processing file: training_data.jsonl\n\n#### Distribution of total tokens:\nmin / max: 37, 41\nmean / median: 38.037142857142854, 38.0\np5 / p95: 37.0, 39.0\n\n#### Distribution of assistant tokens:\nmin / max: 1, 2\nmean / median: 1.1257142857142857, 1.0\np5 / p95: 1.0, 2.0\n**************************************************\nProcessing file: validation_data.jsonl\n\n#### Distribution of total tokens:\nmin / max: 37, 41\nmean / median: 38.013333333333335, 38.0\np5 / p95: 37.0, 39.0\n\n#### Distribution of assistant tokens:\nmin / max: 1, 2\nmean / median: 1.1866666666666668, 1.0\np5 / p95: 1.0, 2.0\n**************************************************\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709154399062
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Upload training files to Azure Open AI"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize AzureOpenAI client\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
        "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
        "  api_version=\"2023-10-01-preview\"  # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002\n",
        ")\n",
        "\n",
        "training_file_name = 'training_data.jsonl'\n",
        "validation_file_name = 'validation_data.jsonl'\n",
        "\n",
        "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
        "\n",
        "training_response = client.files.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "training_file_id = training_response.id\n",
        "\n",
        "validation_response = client.files.create(\n",
        "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "validation_file_id = validation_response.id\n",
        "\n",
        "print(\"Training file ID:\", training_file_id)\n",
        "print(\"Validation file ID:\", validation_file_id)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training file ID: file-1c4a7c22278a49428e8dbedee4b77818\nValidation file ID: file-c794fc59686f49a6a4b0a7fa5f198c7f\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709233800632
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Submit your fine-tuning job"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    validation_file=validation_file_id,\n",
        "    model=\"gpt-35-turbo-0613\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters. \n",
        ")\n",
        "\n",
        "job_id = response.id\n",
        "\n",
        "# You can use the job ID to monitor the status of the fine-tuning job.\n",
        "# The fine-tuning job will take some time to start and complete.\n",
        "\n",
        "print(\"Job ID:\", response.id)\n",
        "print(\"Status:\", response.status)\n",
        "print(response.model_dump_json(indent=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Job ID: ftjob-1478253d632e49b5a4b9d7ba4878c093\nStatus: pending\n{\n  \"id\": \"ftjob-1478253d632e49b5a4b9d7ba4878c093\",\n  \"created_at\": 1709233806,\n  \"error\": null,\n  \"fine_tuned_model\": null,\n  \"finished_at\": null,\n  \"hyperparameters\": {\n    \"n_epochs\": -1,\n    \"batch_size\": -1,\n    \"learning_rate_multiplier\": 1\n  },\n  \"model\": \"gpt-35-turbo-0613\",\n  \"object\": \"fine_tuning.job\",\n  \"organization_id\": null,\n  \"result_files\": null,\n  \"status\": \"pending\",\n  \"trained_tokens\": null,\n  \"training_file\": \"file-1c4a7c22278a49428e8dbedee4b77818\",\n  \"validation_file\": \"file-c794fc59686f49a6a4b0a7fa5f198c7f\",\n  \"updated_at\": 1709233806\n}\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709233805984
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Track Training Status"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Track training status\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Get the status of our fine-tuning job.\n",
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "status = response.status\n",
        "\n",
        "# If the job isn't done yet, poll it every 10 seconds.\n",
        "while status not in [\"succeeded\", \"failed\"]:\n",
        "    time.sleep(10)\n",
        "    \n",
        "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "    print(response.model_dump_json(indent=2))\n",
        "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
        "    status = response.status\n",
        "    print(f'Status: {status}')\n",
        "    clear_output(wait=True)\n",
        "\n",
        "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
        "\n",
        "# List all fine-tuning jobs for this resource.\n",
        "print('Checking other fine-tune jobs for this resource.')\n",
        "response = client.fine_tuning.jobs.list()\n",
        "print(f'Found {len(response.data)} fine-tune jobs.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"ftjob-1478253d632e49b5a4b9d7ba4878c093\",\n  \"created_at\": 1709233806,\n  \"error\": null,\n  \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-1478253d632e49b5a4b9d7ba4878c093\",\n  \"finished_at\": 1709237242,\n  \"hyperparameters\": {\n    \"n_epochs\": -1,\n    \"batch_size\": -1,\n    \"learning_rate_multiplier\": 1\n  },\n  \"model\": \"gpt-35-turbo-0613\",\n  \"object\": \"fine_tuning.job\",\n  \"organization_id\": null,\n  \"result_files\": [\n    \"file-8b260538c8874385a100fed1c0df0e61\"\n  ],\n  \"status\": \"succeeded\",\n  \"trained_tokens\": -13313,\n  \"training_file\": \"file-1c4a7c22278a49428e8dbedee4b77818\",\n  \"validation_file\": \"file-c794fc59686f49a6a4b0a7fa5f198c7f\",\n  \"updated_at\": 1709237242\n}\nElapsed time: 56 minutes 24 seconds\nStatus: succeeded\nFine-tuning job ftjob-1478253d632e49b5a4b9d7ba4878c093 finished with status: succeeded\nChecking other fine-tune jobs for this resource.\nFound 3 fine-tune jobs.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709237242576
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Retrieve Fine Tuned Model Name"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "print(response.model_dump_json(indent=2))\n",
        "fine_tuned_model = response.fine_tuned_model"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n  \"id\": \"ftjob-1478253d632e49b5a4b9d7ba4878c093\",\n  \"created_at\": 1709233806,\n  \"error\": null,\n  \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-1478253d632e49b5a4b9d7ba4878c093\",\n  \"finished_at\": 1709237242,\n  \"hyperparameters\": {\n    \"n_epochs\": -1,\n    \"batch_size\": -1,\n    \"learning_rate_multiplier\": 1\n  },\n  \"model\": \"gpt-35-turbo-0613\",\n  \"object\": \"fine_tuning.job\",\n  \"organization_id\": null,\n  \"result_files\": [\n    \"file-8b260538c8874385a100fed1c0df0e61\"\n  ],\n  \"status\": \"succeeded\",\n  \"trained_tokens\": -13313,\n  \"training_file\": \"file-1c4a7c22278a49428e8dbedee4b77818\",\n  \"validation_file\": \"file-c794fc59686f49a6a4b0a7fa5f198c7f\",\n  \"updated_at\": 1709237242\n}\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709238394955
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9 : Deploy a fine-tuned model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "token= os.getenv(\"TEMP_AUTH_TOKEN\") \n",
        "subscription = \"559395b4-36ba-437a-a7c1-224ff54723e0\"  \n",
        "resource_group = \"AOAI-Shared\"\n",
        "resource_name = \"AOAI-SwedenCentral-4All\"\n",
        "model_deployment_name =\"gpt-35-turbo\"\n",
        "\n",
        "deploy_params = {'api-version': \"2023-10-01-preview\"} \n",
        "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
        "\n",
        "deploy_data = {\n",
        "    \"sku\": {\"name\": \"standard\", \"capacity\": 1}, \n",
        "    \"properties\": {\n",
        "        \"model\": {\n",
        "            \"format\": \"OpenAI\",\n",
        "            \"name\": \"gpt-35-turbo-0613.ft-1478253d632e49b5a4b9d7ba4878c093\", #retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
        "            \"version\": \"3\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "deploy_data = json.dumps(deploy_data)\n",
        "\n",
        "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
        "\n",
        "print('Creating a new deployment...')\n",
        "\n",
        "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
        "\n",
        "print(r)\n",
        "print(r.reason)\n",
        "print(r.json())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Creating a new deployment...\n<Response [201]>\nCreated\n{'id': '/subscriptions/559395b4-36ba-437a-a7c1-224ff54723e0/resourceGroups/AOAI-Shared/providers/Microsoft.CognitiveServices/accounts/AOAI-SwedenCentral-4All/deployments/gpt-35-turbo', 'type': 'Microsoft.CognitiveServices/accounts/deployments', 'name': 'gpt-35-turbo', 'sku': {'name': 'standard', 'capacity': 1}, 'properties': {'model': {'format': 'OpenAI', 'name': 'gpt-35-turbo-0613.ft-1478253d632e49b5a4b9d7ba4878c093', 'version': '3'}, 'versionUpgradeOption': 'NoAutoUpgrade', 'currentCapacity': 1, 'capabilities': {'chatCompletion': 'true'}, 'provisioningState': 'Creating', 'rateLimits': [{'key': 'request', 'renewalPeriod': 10, 'count': 1}, {'key': 'token', 'renewalPeriod': 60, 'count': 1000}]}, 'systemData': {'createdBy': 'anurag.sirish@gmail.com', 'createdByType': 'User', 'createdAt': '2024-02-29T20:34:38.2610458Z', 'lastModifiedBy': 'anurag.sirish@gmail.com', 'lastModifiedByType': 'User', 'lastModifiedAt': '2024-02-29T20:34:38.2610458Z'}, 'etag': '\"9c967f0f-80a3-4884-8d0d-9b4b1f7fb6ea\"'}\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709238886001
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Testing 1\n",
        "\n",
        "### Classifies a complex question as 'Legal' accurately"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
        "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
        "  api_version=\"2023-10-01-preview\"\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-35-turbo\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a classification model. Classify questions into different domains.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Is a verbal agreement enforceable when no written documentation exists, and under what circumstances might it be recognized?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Legal\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709239840519
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Testing 2\n",
        "\n",
        "### Classifies a complex question as 'HR' accurately"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-35-turbo\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a classification model. Classify questions into different domains.\"},\n",
        "        {\"role\": \"user\", \"content\": \"In a situation where an individual reports feeling targeted due to a characteristic protected by federal standards and experiences conduct contributing to an unwelcoming work atmosphere, what steps should be taken to initiate a thorough internal review to ensure adherence to relevant statutes, while also protecting the privacy and rights of everyone involved, and what actions are necessary to maintain team cohesion and efficiency throughout this period?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "HR\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709240017285
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge: Now use the test dataset questions provided and evaluate the model for accuracy"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
